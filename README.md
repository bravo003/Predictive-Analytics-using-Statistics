# **Sampling**
Analyzing different sampling techniques
This project compares the performance of 5 different machine learning models on 5 different sampling techniques for imbalanced datasets.

## The sampling techniques used in this project are:
### Probability Sampling:
1. Random OverSampler
2. SMOTE (Synthetic Minority Over-sampling Technique)

### Non-Probability Sampling:
1. Random UnderSampler
2. SMOTE-ENN (SMOTE + Edited Nearest Neighbors)
3. SMOTE-Tomek

## The machine learning models used in this project are:
1. Random Forest
2. Logistic Regression
3. XGBoost
4. KNN
5. SVM

